{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe8dc84-8e4f-4fe0-9ee9-a67ccbb7126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# =========================\n",
    "#  Load dataset\n",
    "# =========================\n",
    "df = pd.read_csv(\"defenders_5seasons_modelready.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d4685b0-b2b9-4eb2-ae5a-43b183ef5131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows - All: 387 CB: 190 FB: 197\n",
      "Saved:\n",
      " - defenders_all_prepared.csv\n",
      " - defenders_cb_prepared.csv\n",
      " - defenders_fb_prepared.csv\n",
      "\n",
      "Random Forest - All Defenders RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.449\n",
      "Macro F1: 0.373\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 5  2 11  0]\n",
      " [ 3  1  5  3]\n",
      " [ 2  0 20  5]\n",
      " [ 1  0 11  9]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.28      0.34        18\n",
      "           1       0.33      0.08      0.13        12\n",
      "           2       0.43      0.74      0.54        27\n",
      "           3       0.53      0.43      0.47        21\n",
      "\n",
      "    accuracy                           0.45        78\n",
      "   macro avg       0.44      0.38      0.37        78\n",
      "weighted avg       0.45      0.45      0.41        78\n",
      "\n",
      "\n",
      "Random Forest - Centre Backs RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.316\n",
      "Macro F1: 0.255\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5 0 3 1]\n",
      " [4 0 3 0]\n",
      " [3 1 5 3]\n",
      " [4 0 4 2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.56      0.40         9\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.33      0.42      0.37        12\n",
      "           3       0.33      0.20      0.25        10\n",
      "\n",
      "    accuracy                           0.32        38\n",
      "   macro avg       0.24      0.29      0.26        38\n",
      "weighted avg       0.27      0.32      0.28        38\n",
      "\n",
      "\n",
      "Random Forest - Full Backs RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.4\n",
      "Macro F1: 0.285\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1 0 8 0]\n",
      " [0 0 3 2]\n",
      " [2 0 9 4]\n",
      " [0 0 5 6]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.17         9\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.36      0.60      0.45        15\n",
      "           3       0.50      0.55      0.52        11\n",
      "\n",
      "    accuracy                           0.40        40\n",
      "   macro avg       0.30      0.31      0.28        40\n",
      "weighted avg       0.35      0.40      0.35        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------------------------\n",
    "# Encode tier_league for classification\n",
    "# -------------------------\n",
    "df[\"tier_league_class\"] = pd.cut(\n",
    "    df[\"tier_league\"],\n",
    "    bins=[-0.1, 0.16, 0.5, 0.8, 1.1],\n",
    "    labels=[0, 1, 2, 3]\n",
    ").astype(int)\n",
    "\n",
    "# =========================\n",
    "#  Tracking columns & target\n",
    "# =========================\n",
    "desired_tracking_cols = ['player', 'team', 'season', 'age', 'role', 'tier_league']\n",
    "tracking_cols = [c for c in desired_tracking_cols if c in df.columns]\n",
    "\n",
    "target_col = 'tier_league_class'\n",
    "position_col = 'role'   \n",
    "\n",
    "# Clean role values (CB / FB etc.)\n",
    "df[position_col] = df[position_col].astype(str).str.strip().str.upper()\n",
    "\n",
    "# =========================\n",
    "#  Split into 3 datasets: All / CB / FB\n",
    "# =========================\n",
    "df_all = df.copy()\n",
    "df_cb = df[df[position_col] == 'CB'].copy()\n",
    "df_fb = df[df[position_col] == 'FB'].copy()\n",
    "\n",
    "print(\"Rows - All:\", len(df_all), \"CB:\", len(df_cb), \"FB:\", len(df_fb))\n",
    "\n",
    "# =========================\n",
    "#  Helper: prepare dataset \n",
    "# =========================\n",
    "def prepare_dataset(df, tracking_cols, target_col):\n",
    "    # Target (discrete classes)\n",
    "    y = df[target_col].copy()\n",
    "\n",
    "    # Features = everything except tracking + target\n",
    "    X = df.drop(columns=tracking_cols + [target_col])\n",
    "\n",
    "    # Tracking info (for later reference / joins)\n",
    "    tracking_info = df[tracking_cols].copy()\n",
    "\n",
    "    # Normalise features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=df.index)\n",
    "\n",
    "    return X_scaled, y, tracking_info, scaler\n",
    "\n",
    "# Prepare all three\n",
    "X_all, y_all, track_all, scaler_all = prepare_dataset(df_all, tracking_cols, target_col)\n",
    "X_cb,  y_cb,  track_cb,  scaler_cb  = prepare_dataset(df_cb,  tracking_cols, target_col)\n",
    "X_fb,  y_fb,  track_fb,  scaler_fb  = prepare_dataset(df_fb,  tracking_cols, target_col)\n",
    "\n",
    "# =========================\n",
    "#  Save prepared datasets to CSV\n",
    "# =========================\n",
    "df_all_prepared = pd.concat([track_all, X_all, y_all.rename(\"tier_league_class\")], axis=1)\n",
    "df_cb_prepared  = pd.concat([track_cb,  X_cb,  y_cb.rename(\"tier_league_class\")],  axis=1)\n",
    "df_fb_prepared  = pd.concat([track_fb,  X_fb,  y_fb.rename(\"tier_league_class\")],  axis=1)\n",
    "\n",
    "df_all_prepared.to_csv(\"defenders_all_prepared.csv\", index=False)\n",
    "df_cb_prepared.to_csv(\"defenders_cb_prepared.csv\", index=False)\n",
    "df_fb_prepared.to_csv(\"defenders_fb_prepared.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - defenders_all_prepared.csv\")\n",
    "print(\" - defenders_cb_prepared.csv\")\n",
    "print(\" - defenders_fb_prepared.csv\")\n",
    "\n",
    "# =========================\n",
    "#  Random Forest and metrics\n",
    "# =========================\n",
    "def train_random_forest(X, y, name=\"Model\"):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n{name} RESULTS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Accuracy:\", round(acc, 3))\n",
    "    print(\"Macro F1:\", round(f1, 3))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    return rf, (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# =========================\n",
    "# Train models\n",
    "# =========================\n",
    "rf_all, (X_train_all, X_test_all, y_train_all, y_test_all) = \\\n",
    "    train_random_forest(X_all, y_all, name=\"Random Forest - All Defenders\")\n",
    "\n",
    "rf_cb, (X_train_cb, X_test_cb, y_train_cb, y_test_cb) = \\\n",
    "    train_random_forest(X_cb, y_cb, name=\"Random Forest - Centre Backs\")\n",
    "\n",
    "rf_fb, (X_train_fb, X_test_fb, y_train_fb, y_test_fb) = \\\n",
    "    train_random_forest(X_fb, y_fb, name=\"Random Forest - Full Backs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04d57746-132e-4d0b-8b55-8634c6b617eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def select_features(\n",
    "    df,\n",
    "    target_col,\n",
    "    tracking_cols,\n",
    "    corr_threshold=0.10,\n",
    "    imp_threshold=0.02,\n",
    "    redundancy_threshold=0.90,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Automatic feature selection based on:\n",
    "      - |correlation with target| >= corr_threshold  OR\n",
    "      - RF feature importance >= imp_threshold\n",
    "    and then removing highly-redundant features (|corr| between features >= redundancy_threshold)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    numeric_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "    \n",
    "    candidate_features = [\n",
    "        c for c in numeric_cols if c not in tracking_cols + [target_col]\n",
    "    ]\n",
    "\n",
    "    # ---- Correlation with target ----\n",
    "    corr_with_target = df[candidate_features + [target_col]].corr()[target_col].drop(target_col)\n",
    "    corr_keep = corr_with_target[abs(corr_with_target) >= corr_threshold].index.tolist()\n",
    "\n",
    "    # ---- Random Forest importance ----\n",
    "    X = df[candidate_features]\n",
    "    y = df[target_col]\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    importances = pd.Series(rf.feature_importances_, index=candidate_features)\n",
    "    imp_keep = importances[importances >= imp_threshold].index.tolist()\n",
    "\n",
    "    \n",
    "    initial_selected = sorted(list(set(corr_keep) | set(imp_keep)))\n",
    "\n",
    "    # Remove redundant features \n",
    "    if len(initial_selected) == 0:\n",
    "        raise ValueError(\"No features selected\")\n",
    "\n",
    "    corr_matrix = df[initial_selected].corr().abs()\n",
    "\n",
    "    # greedy procedure\n",
    "    selected_final = []\n",
    "    for col in initial_selected:\n",
    "        \n",
    "        if all(corr_matrix.loc[col, kept] < redundancy_threshold for kept in selected_final):\n",
    "            selected_final.append(col)\n",
    "\n",
    "    \n",
    "    selected_final = sorted(selected_final)\n",
    "\n",
    "    return {\n",
    "        \"selected_features\": selected_final,\n",
    "        \"corr_with_target\": corr_with_target.sort_values(ascending=False),\n",
    "        \"rf_importances\": importances.sort_values(ascending=False)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "000146e3-e604-468b-8a77-a3dd1c88ab50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final selected features (after all rules) ===\n",
      "aerial_duels_won_per90\n",
      "aerial_win_pct\n",
      "assists_per90\n",
      "att_90\n",
      "att_pen\n",
      "avg_pass_distance\n",
      "carries_per90\n",
      "carry_progressive_distance\n",
      "clearances\n",
      "defensive_actions_in_penalty_area\n",
      "expected_assists\n",
      "expected_goals_plus_assists\n",
      "fouls_committed\n",
      "goal_creating_actions_per90\n",
      "goals_plus_assists_per90\n",
      "has_goals_shot_event\n",
      "has_goals_shot_on_target_event\n",
      "interceptions\n",
      "non_penalty_expected_goals\n",
      "non_penalty_xg_per_shot\n",
      "pass_completion_pct\n",
      "passes_completed_into_penalty_area\n",
      "passes_into_penalty_area\n",
      "progressive_carries\n",
      "progressive_passes\n",
      "progressive_passes_received\n",
      "recoveries_per90_extra\n",
      "red_cards\n",
      "shot_creating_actions_per90\n",
      "shots_on_target_pct\n",
      "shots_per90\n",
      "tackle_success_pct\n",
      "tackles_in_defensive_third\n",
      "tackles_won\n",
      "touches_per90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# feature selection on ALL defenders \n",
    "fs_result = select_features(\n",
    "    df=df,\n",
    "    target_col=target_col,\n",
    "    tracking_cols=tracking_cols,\n",
    "    corr_threshold=0.10,\n",
    "    imp_threshold=0.02,\n",
    "    redundancy_threshold=0.90,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "selected_features = fs_result[\"selected_features\"]\n",
    "\n",
    "print(\"\\n=== Final selected features ===\")\n",
    "for f in selected_features:\n",
    "    print(f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9a996ea-9546-475e-bbdd-bf4576c74dad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top correlations with target:\n",
      " carries_per90                     0.364662\n",
      "recoveries_per90                  0.358882\n",
      "carry_progressive_distance        0.354252\n",
      "completed_passes_per90            0.341681\n",
      "touches_per90                     0.318845\n",
      "att_pen                           0.315823\n",
      "pass_completion_pct               0.256367\n",
      "progressive_passes                0.203772\n",
      "goals_plus_assists_per90          0.193972\n",
      "assists_per90                     0.187246\n",
      "progressive_carries               0.181344\n",
      "live_ball_passes                  0.177320\n",
      "goal_creating_actions_per90       0.172552\n",
      "shots_per90                       0.165421\n",
      "progressive_passes_received       0.163220\n",
      "aerial_win_pct                    0.160419\n",
      "non_penalty_expected_goals        0.159069\n",
      "has_goals_shot_on_target_event    0.157196\n",
      "expected_assists                  0.147811\n",
      "successful_actions                0.146196\n",
      "Name: tier_league_class, dtype: float64\n",
      "\n",
      "Top RF feature importances:\n",
      " carries_per90                        0.038605\n",
      "carry_progressive_distance           0.037256\n",
      "pass_completion_pct                  0.035339\n",
      "recoveries_per90                     0.032555\n",
      "aerial_win_pct                       0.031189\n",
      "touches_per90                        0.030820\n",
      "att_pen                              0.029510\n",
      "completed_passes_per90               0.028437\n",
      "avg_pass_distance                    0.027332\n",
      "recoveries_per90_extra               0.026857\n",
      "tackle_success_pct                   0.026791\n",
      "clearances                           0.025939\n",
      "aerial_duels_won_per90               0.025630\n",
      "progressive_passes                   0.022871\n",
      "defensive_actions_in_penalty_area    0.022303\n",
      "interceptions                        0.021471\n",
      "tackles_won                          0.020882\n",
      "non_penalty_xg_per_shot              0.020678\n",
      "fouls_committed                      0.020423\n",
      "progressive_carries                  0.020268\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop correlations with target:\\n\", fs_result[\"corr_with_target\"].head(20))\n",
    "print(\"\\nTop RF feature importances:\\n\", fs_result[\"rf_importances\"].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b2f226f-3511-44dc-848a-25b2fe2b8d60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows - All: 387 CB: 190 FB: 197\n",
      "\n",
      "Saved reduced-feature datasets:\n",
      " - defenders_all_prepared_reduced_features.csv\n",
      " - defenders_cb_prepared_reduced_features.csv\n",
      " - defenders_fb_prepared_reduced_features.csv\n",
      "\n",
      "Random Forest - All Defenders (reduced features) RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.474\n",
      "Macro F1: 0.406\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7  1 10  0]\n",
      " [ 2  1  7  2]\n",
      " [ 1  0 20  6]\n",
      " [ 2  0 10  9]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.39      0.47        18\n",
      "           1       0.50      0.08      0.14        12\n",
      "           2       0.43      0.74      0.54        27\n",
      "           3       0.53      0.43      0.47        21\n",
      "\n",
      "    accuracy                           0.47        78\n",
      "   macro avg       0.51      0.41      0.41        78\n",
      "weighted avg       0.50      0.47      0.44        78\n",
      "\n",
      "\n",
      "Random Forest - Centre Backs (reduced features) RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.316\n",
      "Macro F1: 0.256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5 0 4 0]\n",
      " [3 0 4 0]\n",
      " [3 1 5 3]\n",
      " [5 0 3 2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.56      0.40         9\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.31      0.42      0.36        12\n",
      "           3       0.40      0.20      0.27        10\n",
      "\n",
      "    accuracy                           0.32        38\n",
      "   macro avg       0.26      0.29      0.26        38\n",
      "weighted avg       0.28      0.32      0.28        38\n",
      "\n",
      "\n",
      "Random Forest - Full Backs (reduced features) RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.425\n",
      "Macro F1: 0.326\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2 0 7 0]\n",
      " [2 0 2 1]\n",
      " [3 0 8 4]\n",
      " [0 0 4 7]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.22      0.25         9\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.38      0.53      0.44        15\n",
      "           3       0.58      0.64      0.61        11\n",
      "\n",
      "    accuracy                           0.42        40\n",
      "   macro avg       0.31      0.35      0.33        40\n",
      "weighted avg       0.37      0.42      0.39        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "position_col = \"role\"\n",
    "df[position_col] = df[position_col].astype(str).str.strip().str.upper()\n",
    "\n",
    "# ========= Split into ALL / CB / FB =========\n",
    "df_all = df.copy()\n",
    "df_cb = df[df[position_col] == \"CB\"].copy()\n",
    "df_fb = df[df[position_col] == \"FB\"].copy()\n",
    "\n",
    "print(\"Rows - All:\", len(df_all), \"CB:\", len(df_cb), \"FB:\", len(df_fb))\n",
    "\n",
    "# ========= prepare dataset =========\n",
    "def prepare_dataset(df_subset, tracking_cols, target_col, feature_list):\n",
    "    # restrict features to those present in this subset\n",
    "    feature_cols = [c for c in feature_list if c in df_subset.columns]\n",
    "\n",
    "    y = df_subset[target_col].copy()\n",
    "    X = df_subset[feature_cols].copy()\n",
    "\n",
    "    tracking_info = df_subset[tracking_cols].copy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=feature_cols, index=df_subset.index)\n",
    "\n",
    "    return X_scaled, y, tracking_info, scaler\n",
    "\n",
    "# Prepare all three datasets\n",
    "X_all, y_all, track_all, scaler_all = prepare_dataset(df_all, tracking_cols, target_col, selected_features)\n",
    "X_cb,  y_cb,  track_cb,  scaler_cb  = prepare_dataset(df_cb,  tracking_cols, target_col, selected_features)\n",
    "X_fb,  y_fb,  track_fb,  scaler_fb  = prepare_dataset(df_fb,  tracking_cols, target_col, selected_features)\n",
    "\n",
    "\n",
    "df_all_prepared = pd.concat([track_all, X_all, y_all.rename(\"tier_league_class\")], axis=1)\n",
    "df_cb_prepared  = pd.concat([track_cb,  X_cb,  y_cb.rename(\"tier_league_class\")],  axis=1)\n",
    "df_fb_prepared  = pd.concat([track_fb,  X_fb,  y_fb.rename(\"tier_league_class\")],  axis=1)\n",
    "\n",
    "df_all_prepared.to_csv(\"defenders_all_prepared_reduced_features.csv\", index=False)\n",
    "df_cb_prepared.to_csv(\"defenders_cb_prepared_reduced_features.csv\", index=False)\n",
    "df_fb_prepared.to_csv(\"defenders_fb_prepared_reduced_features.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved reduced-feature datasets:\")\n",
    "print(\" - defenders_all_prepared_reduced_features.csv\")\n",
    "print(\" - defenders_cb_prepared_reduced_features.csv\")\n",
    "print(\" - defenders_fb_prepared_reduced_features.csv\")\n",
    "\n",
    "# ========= RF training helper =========\n",
    "def train_random_forest(X, y, name=\"Model\"):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n{name} RESULTS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Accuracy:\", round(acc, 3))\n",
    "    print(\"Macro F1:\", round(f1, 3))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    return rf, (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# ========= Train models on reduced-feature datasets =========\n",
    "rf_all, _ = train_random_forest(X_all, y_all, name=\"Random Forest - All Defenders (reduced features)\")\n",
    "rf_cb,  _ = train_random_forest(X_cb,  y_cb,  name=\"Random Forest - Centre Backs (reduced features)\")\n",
    "rf_fb,  _ = train_random_forest(X_fb,  y_fb,  name=\"Random Forest - Full Backs (reduced features)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a8db125-fcc5-407b-a174-c716d3ce70cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\jsava\\anaconda3\\lib\\site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\jsava\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\jsava\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\jsava\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\jsava\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jsava\\anaconda3\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1584afb2-71d1-4558-a211-576f92124c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85066b22-14bc-43e5-97db-e98a7d6adaab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest - All Defenders (SMOTE) RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.423\n",
      "Macro F1: 0.382\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 6  4  8  0]\n",
      " [ 4  2  4  2]\n",
      " [ 5  0 16  6]\n",
      " [ 3  0  9  9]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33        18\n",
      "           1       0.33      0.17      0.22        12\n",
      "           2       0.43      0.59      0.50        27\n",
      "           3       0.53      0.43      0.47        21\n",
      "\n",
      "    accuracy                           0.42        78\n",
      "   macro avg       0.41      0.38      0.38        78\n",
      "weighted avg       0.42      0.42      0.41        78\n",
      "\n",
      "\n",
      "Random Forest - Centre Backs (SMOTE) RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.342\n",
      "Macro F1: 0.3\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5 1 3 0]\n",
      " [5 0 2 0]\n",
      " [3 2 5 2]\n",
      " [4 1 2 3]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.56      0.38         9\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.42      0.42      0.42        12\n",
      "           3       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.34        38\n",
      "   macro avg       0.33      0.32      0.30        38\n",
      "weighted avg       0.36      0.34      0.33        38\n",
      "\n",
      "\n",
      "Random Forest - Full Backs (SMOTE) RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.425\n",
      "Macro F1: 0.39\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2 1 5 1]\n",
      " [2 1 2 0]\n",
      " [5 0 6 4]\n",
      " [0 0 3 8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.22      0.22         9\n",
      "           1       0.50      0.20      0.29         5\n",
      "           2       0.38      0.40      0.39        15\n",
      "           3       0.62      0.73      0.67        11\n",
      "\n",
      "    accuracy                           0.42        40\n",
      "   macro avg       0.43      0.39      0.39        40\n",
      "weighted avg       0.42      0.42      0.41        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_random_forest_with_smote(X, y, name=\"Model\"):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Apply SMOTE only on training data\n",
    "    sm = SMOTE(random_state=42, k_neighbors=3)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train_res, y_train_res)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n{name} (SMOTE) RESULTS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Accuracy:\", round(acc, 3))\n",
    "    print(\"Macro F1:\", round(f1, 3))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    return rf\n",
    "\n",
    "\n",
    "# Train models on all 3 datasets with SMOTE\n",
    "rf_all_smote = train_random_forest_with_smote(X_all, y_all, name=\"Random Forest - All Defenders\")\n",
    "rf_cb_smote  = train_random_forest_with_smote(X_cb,  y_cb,  name=\"Random Forest - Centre Backs\")\n",
    "rf_fb_smote  = train_random_forest_with_smote(X_fb,  y_fb,  name=\"Random Forest - Full Backs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a75e096e-5bda-4571-9e8c-b48903e19c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Helper\n",
    "\n",
    "def load_prepared_dataset(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # Tracking columns\n",
    "    tracking_cols = [c for c in [\"player\", \"team\", \"season\", \"age\", \"role\", \"tier_league\"]\n",
    "                     if c in df.columns]\n",
    "    \n",
    "    target_col = \"tier_league_class\"\n",
    "    \n",
    "    y = df[target_col].copy()\n",
    "    X = df.drop(columns=tracking_cols + [target_col])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Helper\n",
    "\n",
    "def evaluate_sklearn_model(model, X, y, name=\"Model\"):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{name} RESULTS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Accuracy:\", round(acc, 3))\n",
    "    print(\"Macro F1:\", round(f1, 3))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb6e02b5-5f3f-458b-ba57-5d45c3887faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "def evaluate_tabpfn(X, y, name=\"TabPFN\"):\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Convert to numpy\n",
    "    X_train_np = X_train.to_numpy().astype(\"float32\")\n",
    "    X_test_np  = X_test.to_numpy().astype(\"float32\")\n",
    "    y_train_np = y_train.to_numpy()\n",
    "    y_test_np  = y_test.to_numpy()\n",
    "\n",
    "    clf = TabPFNClassifier(device=\"cpu\")  \n",
    "\n",
    "    clf.fit(X_train_np, y_train_np)\n",
    "\n",
    "    \n",
    "    y_pred = clf.predict(X_test_np)\n",
    "\n",
    "    \n",
    "    acc = accuracy_score(y_test_np, y_pred)\n",
    "    f1 = f1_score(y_test_np, y_pred, average=\"macro\")\n",
    "    cm = confusion_matrix(y_test_np, y_pred)\n",
    "\n",
    "    print(f\"\\n{name} RESULTS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Accuracy:\", round(acc, 3))\n",
    "    print(\"Macro F1:\", round(f1, 3))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test_np, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e01c91b-79fe-4557-b0fa-d83f5ea2c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def build_xgb_classifier(num_classes=4):\n",
    "    return XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=num_classes,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc920cad-d42a-45bf-865c-6d20d7023d51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\tabpfn\\classifier.py:484: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TabPFN - All Defenders RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.436\n",
      "Macro F1: 0.348\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 8  0 10  0]\n",
      " [ 3  0  6  3]\n",
      " [ 3  0 18  6]\n",
      " [ 2  0 11  8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.44      0.47        18\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       0.40      0.67      0.50        27\n",
      "           3       0.47      0.38      0.42        21\n",
      "\n",
      "    accuracy                           0.44        78\n",
      "   macro avg       0.34      0.37      0.35        78\n",
      "weighted avg       0.38      0.44      0.40        78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost - All Defenders RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.436\n",
      "Macro F1: 0.374\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 4  4  9  1]\n",
      " [ 2  2  4  4]\n",
      " [ 3  0 19  5]\n",
      " [ 3  0  9  9]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.22      0.27        18\n",
      "           1       0.33      0.17      0.22        12\n",
      "           2       0.46      0.70      0.56        27\n",
      "           3       0.47      0.43      0.45        21\n",
      "\n",
      "    accuracy                           0.44        78\n",
      "   macro avg       0.40      0.38      0.37        78\n",
      "weighted avg       0.42      0.44      0.41        78\n",
      "\n",
      "\n",
      "TabPFN - Centre Backs RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.263\n",
      "Macro F1: 0.212\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5 0 3 1]\n",
      " [3 0 4 0]\n",
      " [3 1 4 4]\n",
      " [2 0 7 1]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.56      0.45         9\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.22      0.33      0.27        12\n",
      "           3       0.17      0.10      0.12        10\n",
      "\n",
      "    accuracy                           0.26        38\n",
      "   macro avg       0.19      0.25      0.21        38\n",
      "weighted avg       0.21      0.26      0.22        38\n",
      "\n",
      "\n",
      "XGBoost - Centre Backs RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.395\n",
      "Macro F1: 0.352\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6 0 3 0]\n",
      " [4 1 2 0]\n",
      " [3 1 6 2]\n",
      " [4 2 2 2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.67      0.46         9\n",
      "           1       0.25      0.14      0.18         7\n",
      "           2       0.46      0.50      0.48        12\n",
      "           3       0.50      0.20      0.29        10\n",
      "\n",
      "    accuracy                           0.39        38\n",
      "   macro avg       0.39      0.38      0.35        38\n",
      "weighted avg       0.41      0.39      0.37        38\n",
      "\n",
      "\n",
      "TabPFN - Full Backs RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.475\n",
      "Macro F1: 0.354\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 2  0  5  2]\n",
      " [ 2  0  2  1]\n",
      " [ 3  0 10  2]\n",
      " [ 0  0  4  7]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.22      0.25         9\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.48      0.67      0.56        15\n",
      "           3       0.58      0.64      0.61        11\n",
      "\n",
      "    accuracy                           0.47        40\n",
      "   macro avg       0.34      0.38      0.35        40\n",
      "weighted avg       0.40      0.47      0.43        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost - Full Backs RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.475\n",
      "Macro F1: 0.442\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3 1 5 0]\n",
      " [2 1 2 0]\n",
      " [5 0 7 3]\n",
      " [0 0 3 8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.33      0.32         9\n",
      "           1       0.50      0.20      0.29         5\n",
      "           2       0.41      0.47      0.44        15\n",
      "           3       0.73      0.73      0.73        11\n",
      "\n",
      "    accuracy                           0.47        40\n",
      "   macro avg       0.48      0.43      0.44        40\n",
      "weighted avg       0.48      0.47      0.47        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------- All defenders --------\n",
    "X_all, y_all = load_prepared_dataset(\"defenders_all_prepared_reduced_features.csv\")\n",
    "\n",
    "evaluate_tabpfn(X_all, y_all, name=\"TabPFN - All Defenders\")\n",
    "\n",
    "xgb_all = build_xgb_classifier(num_classes=len(np.unique(y_all)))\n",
    "evaluate_sklearn_model(xgb_all, X_all, y_all, name=\"XGBoost - All Defenders\")\n",
    "\n",
    "# -------- Centre backs --------\n",
    "X_cb, y_cb = load_prepared_dataset(\"defenders_cb_prepared_reduced_features.csv\")\n",
    "\n",
    "evaluate_tabpfn(X_cb, y_cb, name=\"TabPFN - Centre Backs\")\n",
    "\n",
    "xgb_cb = build_xgb_classifier(num_classes=len(np.unique(y_cb)))\n",
    "evaluate_sklearn_model(xgb_cb, X_cb, y_cb, name=\"XGBoost - Centre Backs\")\n",
    "\n",
    "# -------- Full backs --------\n",
    "X_fb, y_fb = load_prepared_dataset(\"defenders_fb_prepared_reduced_features.csv\")\n",
    "\n",
    "evaluate_tabpfn(X_fb, y_fb, name=\"TabPFN - Full Backs\")\n",
    "\n",
    "xgb_fb = build_xgb_classifier(num_classes=len(np.unique(y_fb)))\n",
    "evaluate_sklearn_model(xgb_fb, X_fb, y_fb, name=\"XGBoost - Full Backs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71a3f865-2d8e-49d7-bc24-10426cb40c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a5e636a8-efa9-4924-9323-f0a362f13a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbmNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: xgboost in c:\\users\\jsava\\anaconda3\\lib\\site-packages (3.1.1)\n",
      "Collecting mord\n",
      "  Downloading mord-0.7.tar.gz (8.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\jsava\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\jsava\\anaconda3\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 6.9 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: mord\n",
      "  Building wheel for mord (setup.py): started\n",
      "  Building wheel for mord (setup.py): finished with status 'done'\n",
      "  Created wheel for mord: filename=mord-0.7-py3-none-any.whl size=9897 sha256=bb362925db0707d7a4ceba0d44033573ba140b681c01c56825eb8871d73ed158\n",
      "  Stored in directory: c:\\users\\jsava\\appdata\\local\\pip\\cache\\wheels\\80\\3e\\3b\\13f1adf346cad0fec675db328e4b0d814795c6c8e2fb659122\n",
      "Successfully built mord\n",
      "Installing collected packages: mord, lightgbm\n",
      "Successfully installed lightgbm-4.6.0 mord-0.7\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm xgboost mord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5b429032-4671-4576-bdb5-73d709b22c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import mord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "300e29ed-60be-4e0d-b748-fe3bca207c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3-class file to: defenders_all_3class.csv\n",
      "Saved 3-class file to: defenders_cb_3class.csv\n",
      "Saved 3-class file to: defenders_fb_3class.csv\n"
     ]
    }
   ],
   "source": [
    "def add_3class_labels(path_in, path_out):\n",
    "    df = pd.read_csv(path_in)\n",
    "    \n",
    "    \n",
    "    if \"tier_league_class\" not in df.columns:\n",
    "        raise ValueError(f\"'tier_league_class' not found in {path_in}\")\n",
    "    \n",
    "    # Map 4-class -> 3-class\n",
    "    mapping = {\n",
    "        0: 0,  # poor\n",
    "        1: 1,  # mid\n",
    "        2: 1,  # mid\n",
    "        3: 2   # top\n",
    "    }\n",
    "    df[\"tier_3class\"] = df[\"tier_league_class\"].map(mapping).astype(int)\n",
    "    \n",
    "    \n",
    "    df.to_csv(path_out, index=False)\n",
    "    print(f\"Saved 3-class file to: {path_out}\")\n",
    "    return df\n",
    "\n",
    "# All defenders\n",
    "df_all_3 = add_3class_labels(\n",
    "    \"defenders_all_prepared_reduced_features.csv\",\n",
    "    \"defenders_all_3class.csv\"\n",
    ")\n",
    "\n",
    "# Centre backs\n",
    "df_cb_3 = add_3class_labels(\n",
    "    \"defenders_cb_prepared_reduced_features.csv\",\n",
    "    \"defenders_cb_3class.csv\"\n",
    ")\n",
    "\n",
    "# Full backs\n",
    "df_fb_3 = add_3class_labels(\n",
    "    \"defenders_fb_prepared_reduced_features.csv\",\n",
    "    \"defenders_fb_3class.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "08850ada-4903-4a39-b3a1-1c284d210cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking columns\n",
    "TRACKING_COLS = [\"player\", \"team\", \"season\", \"age\", \"role\", \"tier_league\", \"tier_league_class\"]\n",
    "\n",
    "def load_3class_dataset(path, target_col=\"tier_3class\"):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # Keep tracking cols only if they exist\n",
    "    tracking_cols = [c for c in TRACKING_COLS if c in df.columns]\n",
    "    \n",
    "    y = df[target_col].copy()\n",
    "    X = df.drop(columns=tracking_cols + [target_col])\n",
    "    \n",
    "    return X, y, tracking_cols\n",
    "\n",
    "def evaluate_model_clf(model, X, y, name=\"Model\"):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{name} RESULTS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Accuracy:\", round(acc, 3))\n",
    "    print(\"Macro F1:\", round(f1, 3))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    return model, (X_train, X_test, y_train, y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "38a1d7b6-7cca-42a5-8953-7c57d599d5fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def evaluate_lgbm_clean(X, y, name=\"LightGBM\"):\n",
    "    print(f\"\\n{name} RESULTS\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # LightGBM\n",
    "    model = LGBMClassifier(\n",
    "        objective=\"multiclass\",\n",
    "        num_class=3,\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        verbose=-100,               \n",
    "        importance_type=\"gain\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    model.set_params(**{\"callbacks\": []})\n",
    "\n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1  = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    cm  = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", round(acc, 3))\n",
    "    print(\"Macro F1:\", round(f1, 3))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "daeaded9-ec7b-4374-bc33-6e2d82303002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM - All Defenders (3-class) RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.538\n",
      "Macro F1: 0.507\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 8 10  0]\n",
      " [ 5 26  8]\n",
      " [ 2 11  8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.44      0.48        18\n",
      "           1       0.55      0.67      0.60        39\n",
      "           2       0.50      0.38      0.43        21\n",
      "\n",
      "    accuracy                           0.54        78\n",
      "   macro avg       0.53      0.50      0.51        78\n",
      "weighted avg       0.53      0.54      0.53        78\n",
      "\n",
      "\n",
      "LightGBM - Centre Backs (3-class) RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.553\n",
      "Macro F1: 0.528\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 3  5  1]\n",
      " [ 1 12  6]\n",
      " [ 0  4  6]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.33      0.46         9\n",
      "           1       0.57      0.63      0.60        19\n",
      "           2       0.46      0.60      0.52        10\n",
      "\n",
      "    accuracy                           0.55        38\n",
      "   macro avg       0.59      0.52      0.53        38\n",
      "weighted avg       0.58      0.55      0.55        38\n",
      "\n",
      "\n",
      "LightGBM - Full Backs (3-class) RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.425\n",
      "Macro F1: 0.402\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2 6 1]\n",
      " [4 7 9]\n",
      " [0 3 8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.22      0.27         9\n",
      "           1       0.44      0.35      0.39        20\n",
      "           2       0.44      0.73      0.55        11\n",
      "\n",
      "    accuracy                           0.42        40\n",
      "   macro avg       0.41      0.43      0.40        40\n",
      "weighted avg       0.42      0.42      0.41        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all, _ = load_3class_dataset(\"defenders_all_3class.csv\")\n",
    "evaluate_lgbm_clean(X_all, y_all, name=\"LightGBM - All Defenders (3-class)\")\n",
    "\n",
    "X_cb, y_cb, _ = load_3class_dataset(\"defenders_cb_3class.csv\")\n",
    "evaluate_lgbm_clean(X_cb, y_cb, name=\"LightGBM - Centre Backs (3-class)\")\n",
    "\n",
    "X_fb, y_fb, _ = load_3class_dataset(\"defenders_fb_3class.csv\")\n",
    "evaluate_lgbm_clean(X_fb, y_fb, name=\"LightGBM - Full Backs (3-class)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6e641ca5-226f-4a47-8a5d-f2fe09f70096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ordinal LogisticAT - All Defenders (3-class) RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.526\n",
      "Macro F1: 0.425\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 3 15  0]\n",
      " [ 4 32  3]\n",
      " [ 0 15  6]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.17      0.24        18\n",
      "           1       0.52      0.82      0.63        39\n",
      "           2       0.67      0.29      0.40        21\n",
      "\n",
      "    accuracy                           0.53        78\n",
      "   macro avg       0.54      0.42      0.42        78\n",
      "weighted avg       0.54      0.53      0.48        78\n",
      "\n",
      "\n",
      "Ordinal LogisticAT - Centre Backs (3-class) RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.579\n",
      "Macro F1: 0.495\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 2  6  1]\n",
      " [ 1 16  2]\n",
      " [ 0  6  4]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.22      0.33         9\n",
      "           1       0.57      0.84      0.68        19\n",
      "           2       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.58        38\n",
      "   macro avg       0.60      0.49      0.49        38\n",
      "weighted avg       0.59      0.58      0.54        38\n",
      "\n",
      "\n",
      "Ordinal LogisticAT - Full Backs (3-class) RESULTS\n",
      "----------------------------------------\n",
      "Accuracy: 0.55\n",
      "Macro F1: 0.462\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1  7  1]\n",
      " [ 1 14  5]\n",
      " [ 0  4  7]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.11      0.18         9\n",
      "           1       0.56      0.70      0.62        20\n",
      "           2       0.54      0.64      0.58        11\n",
      "\n",
      "    accuracy                           0.55        40\n",
      "   macro avg       0.53      0.48      0.46        40\n",
      "weighted avg       0.54      0.55      0.51        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_mord_ordinal(X, y, name=\"Ordinal LogisticAT\"):\n",
    "    # Mord expects numpy arrays\n",
    "    X_np = X.to_numpy()\n",
    "    y_np = y.to_numpy()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_np, y_np, test_size=0.2, stratify=y_np, random_state=42\n",
    "    )\n",
    "    \n",
    "    model = mord.LogisticAT(alpha=1.0)  \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{name} RESULTS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Accuracy:\", round(acc, 3))\n",
    "    print(\"Macro F1:\", round(f1, 3))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    return model, (X_train, X_test, y_train, y_test, y_pred)\n",
    "\n",
    "\n",
    "X_all, y_all, _ = load_3class_dataset(\"defenders_all_3class.csv\")\n",
    "ord_all, _ = evaluate_mord_ordinal(X_all, y_all, name=\"Ordinal LogisticAT - All Defenders (3-class)\")\n",
    "\n",
    "X_cb, y_cb, _ = load_3class_dataset(\"defenders_cb_3class.csv\")\n",
    "ord_cb, _ = evaluate_mord_ordinal(X_cb, y_cb, name=\"Ordinal LogisticAT - Centre Backs (3-class)\")\n",
    "\n",
    "X_fb, y_fb, _ = load_3class_dataset(\"defenders_fb_3class.csv\")\n",
    "ord_fb, _ = evaluate_mord_ordinal(X_fb, y_fb, name=\"Ordinal LogisticAT - Full Backs (3-class)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fa9caae1-1a9b-4c2a-9504-4729c8684c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xgb(num_classes=3):\n",
    "    model = XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=num_classes,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "313e4321-7234-459a-9c95-cdbbc1e4ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_dist = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [3, 4, 5, 6],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.7, 0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 0.9, 1.0],\n",
    "    \"min_child_weight\": [1, 3, 5],\n",
    "    \"gamma\": [0, 0.5, 1.0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dc3be1cc-a16e-4863-95bd-3edd6a79beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "def tune_xgb(X, y, name=\"XGBoost (tuned)\", n_iter=25):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    num_classes = len(np.unique(y))\n",
    "    base_model = build_xgb(num_classes=num_classes)\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_distributions=xgb_param_dist,\n",
    "        n_iter=n_iter,\n",
    "        scoring=\"f1_macro\",\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "    \n",
    "    print(\"\\nBest parameters found:\")\n",
    "    print(search.best_params_)\n",
    "    \n",
    "    # Evaluate on hold-out test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{name} RESULTS (best model)\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Accuracy:\", round(acc, 3))\n",
    "    print(\"Macro F1:\", round(f1, 3))\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    return best_model, search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b176ea20-dd89-4776-b715-8b4aa56fa9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [21:07:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:\n",
      "{'subsample': 0.9, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 1.0, 'colsample_bytree': 0.8}\n",
      "\n",
      "XGBoost - All Defenders (3-class tuned) RESULTS (best model)\n",
      "----------------------------------------\n",
      "Accuracy: 0.423\n",
      "Macro F1: 0.331\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 2 16  0]\n",
      " [ 6 26  7]\n",
      " [ 2 14  5]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.11      0.14        18\n",
      "           1       0.46      0.67      0.55        39\n",
      "           2       0.42      0.24      0.30        21\n",
      "\n",
      "    accuracy                           0.42        78\n",
      "   macro avg       0.36      0.34      0.33        78\n",
      "weighted avg       0.39      0.42      0.39        78\n",
      "\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [21:07:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:\n",
      "{'subsample': 0.8, 'n_estimators': 600, 'min_child_weight': 3, 'max_depth': 6, 'learning_rate': 0.05, 'gamma': 1.0, 'colsample_bytree': 0.8}\n",
      "\n",
      "XGBoost - Centre Backs (3-class tuned) RESULTS (best model)\n",
      "----------------------------------------\n",
      "Accuracy: 0.711\n",
      "Macro F1: 0.699\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 5  4  0]\n",
      " [ 1 15  3]\n",
      " [ 0  3  7]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.56      0.67         9\n",
      "           1       0.68      0.79      0.73        19\n",
      "           2       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.71        38\n",
      "   macro avg       0.74      0.68      0.70        38\n",
      "weighted avg       0.72      0.71      0.71        38\n",
      "\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsava\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [21:07:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:\n",
      "{'subsample': 0.7, 'n_estimators': 600, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 1.0, 'colsample_bytree': 0.7}\n",
      "\n",
      "XGBoost - Full Backs (3-class tuned) RESULTS (best model)\n",
      "----------------------------------------\n",
      "Accuracy: 0.525\n",
      "Macro F1: 0.491\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 2  7  0]\n",
      " [ 4 10  6]\n",
      " [ 0  2  9]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.22      0.27         9\n",
      "           1       0.53      0.50      0.51        20\n",
      "           2       0.60      0.82      0.69        11\n",
      "\n",
      "    accuracy                           0.53        40\n",
      "   macro avg       0.49      0.51      0.49        40\n",
      "weighted avg       0.50      0.53      0.51        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All defenders\n",
    "X_all, y_all, _ = load_3class_dataset(\"defenders_all_3class.csv\")\n",
    "xgb_best_all, xgb_search_all = tune_xgb(X_all, y_all, name=\"XGBoost - All Defenders (3-class tuned)\", n_iter=30)\n",
    "\n",
    "# Centre backs\n",
    "X_cb, y_cb, _ = load_3class_dataset(\"defenders_cb_3class.csv\")\n",
    "xgb_best_cb, xgb_search_cb = tune_xgb(X_cb, y_cb, name=\"XGBoost - Centre Backs (3-class tuned)\", n_iter=20)\n",
    "\n",
    "# Full backs\n",
    "X_fb, y_fb, _ = load_3class_dataset(\"defenders_fb_3class.csv\")\n",
    "xgb_best_fb, xgb_search_fb = tune_xgb(X_fb, y_fb, name=\"XGBoost - Full Backs (3-class tuned)\", n_iter=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
